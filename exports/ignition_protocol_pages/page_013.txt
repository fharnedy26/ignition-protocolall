 
In short, finishing this “other specs” box: a fuel isn’t just octane/cetane and soot index. It must start in winter, not vapor-lock in summer, atomize correctly, 
lubricate pumps, resist oxidation, meet safety codes, and be pipeline-compatible. Section 3.6 dives deeper into volatility/phase behavior, while later 
methodology chapters show how I encode many of these specs (or surrogates) into my multi-objective fitness so the engine doesn’t hand me a chemically 
“perfect” but operationally useless molecule. 
Computational Benchmarking of the Engine 
In this section, we evaluate the Ignition Protocol's molecular engine primarily as a computational efficiency benchmarking tool rather than as a molecule 
discovery platform. We designed a series of runs under various workload profiles (named Ultra-snappy, Demo, Classroom, Light Stress, Heavy Stress, and 
Brutal) and treated them as stress tests to analyze the engine’s performance and scalability. Our goal here was to push the engine’s computational limits, 
monitor how runtime and throughput scale with workload, and identify bottlenecks – all while de-emphasizing the molecular outputs themselves. The top 
candidate molecules from each run are recorded for completeness (see tables below), but we regard them as byproducts of the performance tests rather 
than optimized discoveries. In other words, a higher-profile run may yield “better” molecules simply because it explores more candidates, not because we 
intentionally tuned chemical search parameters for improved outcomes. The emphasis is on how efficiently the engine can churn through candidates under 
increasing load. 
Engine Structure and Workflow 
The Ignition engine operates in a pipeline of stages – BRICS seeding, mutation, filtering, and scoring – which collectively define its throughput and 
computational load. First, the engine initializes a pool of seed molecules using a BRICS-based approach. BRICS (Breaking of Retrosynthetically Interesting 
Chemical Substructures) is a fragment-based method: it breaks known molecules into fragments at chemically sensible points and allows recombination of 
those fragments. We leverage this to generate starting structures (seed molecules) that cover a broad chemical space of fuel-like compounds. Each seed 
provides a foundation upon which new molecules can be built. In the mutation (generation) stage, the engine iteratively expands or modifies these seeds. 
At each iteration, fragments are attached or substituted according to the BRICS rules, creating new candidate molecules. This is essentially a combinatorial 
growth process – for example, a single seed might spawn several new structures by attaching different fragments at available bond sites. Over multiple 
generations, the number of candidates can grow exponentially if not controlled. For our “toy” engine, we cap the depth and breadth of these mutations per 
the chosen profile (e.g., limiting the number of generations or branches) to manage the total candidates and runtime. Still, as we escalate profiles, the 
combinatorial explosion of possible molecules is a major source of increased load. After each generation, the new candidates pass through a set of filters. 
These filters are fast heuristic checks that eliminate implausible or undesirable structures before investing time in scoring. For instance, we enforce simple 
chemical validity and fuel-relevance filters: candidates must be chemically sound (no valence violations, reasonable sizes) and fall within the expected 
formula domain for fuels (e.g. containing only C/H (hydrocarbon) or limited O content for oxygenates, excluding exotic elements; carbon number within a 
reasonable range, etc.). We also apply quick property estimations as thresholds – for example, rules that screen out molecules with extremely high polarity 
or too many aromatic rings if those are known to be outside fuel-like behavior. These heuristic filters are computationally cheap (simple rule checks or 
fragment count limits), so they drastically prune the candidate list with minimal overhead. This fast first-pass filtering ensures that the subsequent scoring 
stage only deals with candidates that have a fighting chance of being viable, aligning with the strategy discussed earlier in our fuel property heuristics 
section (using inexpensive checks to reduce workload before heavier analysis). The survivors then undergo scoring using surrogate models and heuristics for 
fuel performance. In this toy engine, the scoring function is composed of fuel property surrogate models – essentially algebraic formulas and lightweight 
models that estimate key performance metrics (ignition quality, volatility, energy density, etc.) based on molecular structure. For example, we use 
group-contribution estimates and QSAR-like formulas to predict properties such as cetane number, octane rating, or enthalpy of vaporization. These 
predictions are not as accurate as full physics-based or ML-based predictions, but they are extremely fast to compute. We combine multiple property 
estimates into a single composite “ignition performance score” that the engine tries to maximize. The scoring step is inherently parallelizable (each 
molecule is evaluated independently), but our current implementation computes scores in a simple loop for each candidate. Despite being more complex 
than a trivial lookup, these surrogate calculations are still relatively quick – on the order of milliseconds per molecule or less – which is crucial for handling 
thousands of candidates. The engine then typically selects the top-scoring molecules (or all above a certain score) to carry into the next mutation iteration 
or to report as final results for that profile. Overall, this structure – generate → filter → score (→ repeat) – defines the engine’s computational profile. The 
key computational cost drivers are the number of candidates generated and processed, and the complexity of evaluating each candidate. By design, our 
heavy use of heuristic filtering and simple scoring keeps per-candidate cost low, shifting the challenge toward handling large volumes of candidates 
efficiently. Next, we describe how we scaled these variables in six distinct workload profiles and what we observed in terms of performance. 
12 
